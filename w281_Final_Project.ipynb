{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# W281 Final Project: Intel Image Classification Model #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import Counter\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout,BatchNormalization,MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a16RGOC4-xjw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/zdbrown13/w281/w281_Final_Project_Brown_Benzoni_Olaya\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_images(directory, num_files=5):\n",
        "    images = []\n",
        "    file_list = os.listdir(directory)[:num_files]  # Load only the first 5 files\n",
        "\n",
        "    for filename in tqdm(file_list, desc=f\"Loading images from {directory}\"):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        img = Image.open(img_path)\n",
        "        img = img.resize((150, 150))  # Resize image to 150 x 150\n",
        "        images.append(img)\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Paths\n",
        "\n",
        "buildings_train = './seg_train/buildings'\n",
        "forest_train = './seg_train/forest'\n",
        "glacier_train = './seg_train/glacier'\n",
        "mountain_train = './seg_train/mountain'\n",
        "sea_train = './seg_train/sea'\n",
        "street_train = './seg_train/street'\n",
        "\n",
        "buildings_test = './seg_test/buildings'\n",
        "forest_test = './seg_test/forest'\n",
        "glacier_test = './seg_test/glacier'\n",
        "mountain_test = './seg_test/mountain'\n",
        "sea_test = './seg_test/sea'\n",
        "street_test = './seg_test/street'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading images from ./seg_train/buildings: 100%|██████████| 5/5 [00:00<00:00, 325.65it/s]\n",
            "Loading images from ./seg_train/forest: 100%|██████████| 5/5 [00:00<00:00, 745.04it/s]\n",
            "Loading images from ./seg_train/glacier: 100%|██████████| 5/5 [00:00<00:00, 731.86it/s]\n",
            "Loading images from ./seg_train/mountain: 100%|██████████| 5/5 [00:00<00:00, 935.60it/s]\n",
            "Loading images from ./seg_train/sea: 100%|██████████| 5/5 [00:00<00:00, 790.63it/s]\n",
            "Loading images from ./seg_train/street: 100%|██████████| 5/5 [00:00<00:00, 712.66it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load images from each category\n",
        "buildings_img = load_images(buildings_train)\n",
        "forest_img = load_images(forest_train)\n",
        "glacier_img = load_images(glacier_train)\n",
        "mountain_img = load_images(mountain_train)\n",
        "sea_img = load_images(sea_train)\n",
        "street_img = load_images(street_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buildings_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(datasets):\n",
        "    \n",
        "    output = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        images, labels = [], []\n",
        "        print(f\"Loading {dataset}...\")\n",
        "        i = 0\n",
        "        for folder in os.listdir(dataset):\n",
        "            label = i # Converting word labels to int (i.e. buildings = 0)\n",
        "            i = i+1\n",
        "            folder_path = os.path.join(dataset, folder)\n",
        "\n",
        "            for file in tqdm(os.listdir(folder_path), desc=f\"Processing {folder}\"):\n",
        "                img_path = os.path.join(folder_path, file)\n",
        "\n",
        "                image = Image.open(img_path).resize((150, 150))\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                \n",
        "        images = np.stack(images)\n",
        "        labels = np.array(labels, dtype='int32')\n",
        "        output.append((images, labels))\n",
        "        \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading /Users/zdbrown13/w281/w281_Final_Project_Brown_Benzoni_Olaya/seg_train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing forest: 100%|██████████| 2271/2271 [00:01<00:00, 1179.29it/s]\n",
            "Processing buildings: 100%|██████████| 2191/2191 [00:01<00:00, 1359.23it/s]\n",
            "Processing glacier: 100%|██████████| 2404/2404 [00:01<00:00, 1372.44it/s]\n",
            "Processing street: 100%|██████████| 2382/2382 [00:01<00:00, 1329.97it/s]\n",
            "Processing mountain: 100%|██████████| 2512/2512 [00:01<00:00, 1470.92it/s]\n",
            "Processing sea: 100%|██████████| 2274/2274 [00:01<00:00, 1416.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading /Users/zdbrown13/w281/w281_Final_Project_Brown_Benzoni_Olaya/seg_test...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing forest: 100%|██████████| 474/474 [00:00<00:00, 1039.66it/s]\n",
            "Processing buildings: 100%|██████████| 437/437 [00:00<00:00, 1304.24it/s]\n",
            "Processing glacier: 100%|██████████| 553/553 [00:00<00:00, 1336.87it/s]\n",
            "Processing street: 100%|██████████| 501/501 [00:00<00:00, 1220.35it/s]\n",
            "Processing mountain: 100%|██████████| 525/525 [00:00<00:00, 1446.69it/s]\n",
            "Processing sea: 100%|██████████| 510/510 [00:00<00:00, 1457.25it/s]\n"
          ]
        }
      ],
      "source": [
        "datasets = ['/Users/zdbrown13/w281/w281_Final_Project_Brown_Benzoni_Olaya/seg_train', \n",
        "        '/Users/zdbrown13/w281/w281_Final_Project_Brown_Benzoni_Olaya/seg_test']\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = load_data(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalization\n",
        "train_images = train_images / 255.0 \n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 2271, 1: 2191, 2: 2404, 3: 2382, 4: 2512, 5: 2274}\n"
          ]
        }
      ],
      "source": [
        "# Training Data Distribution\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2339.0\n"
          ]
        }
      ],
      "source": [
        "avg = sum(counts)/len(unique)\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 474, 1: 437, 2: 553, 3: 501, 4: 525, 5: 510}\n"
          ]
        }
      ],
      "source": [
        "# Test Data Distribution\n",
        "test_unique, test_counts = np.unique(test_labels, return_counts=True)\n",
        "print(dict(zip(test_unique, test_counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500.0\n"
          ]
        }
      ],
      "source": [
        "test_avg = sum(test_counts)/len(test_unique)\n",
        "print(test_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
