{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# W281 Final Project: Intel Image Classification Model #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
            "     ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
            "     --------------------------------------- 0.0/11.0 MB 640.0 kB/s eta 0:00:18\n",
            "     --------------------------------------- 0.0/11.0 MB 640.0 kB/s eta 0:00:18\n",
            "     --------------------------------------- 0.1/11.0 MB 871.5 kB/s eta 0:00:13\n",
            "      --------------------------------------- 0.2/11.0 MB 1.1 MB/s eta 0:00:10\n",
            "      --------------------------------------- 0.2/11.0 MB 1.1 MB/s eta 0:00:10\n",
            "      --------------------------------------- 0.2/11.0 MB 1.1 MB/s eta 0:00:10\n",
            "     - -------------------------------------- 0.5/11.0 MB 1.6 MB/s eta 0:00:07\n",
            "     --- ------------------------------------ 0.8/11.0 MB 2.3 MB/s eta 0:00:05\n",
            "     ---- ----------------------------------- 1.2/11.0 MB 3.0 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.2/11.0 MB 3.0 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.2/11.0 MB 3.0 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.3/11.0 MB 2.5 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.3/11.0 MB 2.5 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.3/11.0 MB 2.5 MB/s eta 0:00:04\n",
            "     ----- ---------------------------------- 1.4/11.0 MB 2.0 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 2.1/11.0 MB 2.7 MB/s eta 0:00:04\n",
            "     --------- ------------------------------ 2.7/11.0 MB 3.5 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 2.7/11.0 MB 3.5 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 2.7/11.0 MB 3.5 MB/s eta 0:00:03\n",
            "     ----------- ---------------------------- 3.2/11.0 MB 3.5 MB/s eta 0:00:03\n",
            "     -------------- ------------------------- 3.9/11.0 MB 4.0 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 3.9/11.0 MB 4.0 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 3.9/11.0 MB 4.0 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 4.0/11.0 MB 3.6 MB/s eta 0:00:02\n",
            "     --------------- ------------------------ 4.2/11.0 MB 3.6 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 4.5/11.0 MB 3.7 MB/s eta 0:00:02\n",
            "     ------------------ --------------------- 5.2/11.0 MB 4.2 MB/s eta 0:00:02\n",
            "     --------------------- ------------------ 5.9/11.0 MB 4.5 MB/s eta 0:00:02\n",
            "     ---------------------- ----------------- 6.2/11.0 MB 4.6 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 6.6/11.0 MB 4.7 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 7.2/11.0 MB 5.0 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 7.9/11.0 MB 5.3 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 8.7/11.0 MB 5.7 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 9.7/11.0 MB 6.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 10.6/11.0 MB 7.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------  11.0/11.0 MB 7.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 11.0/11.0 MB 7.6 MB/s eta 0:00:00\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting scipy>=1.6.0\n",
            "  Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
            "     ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.6/44.8 MB 20.1 MB/s eta 0:00:03\n",
            "     - -------------------------------------- 1.3/44.8 MB 14.3 MB/s eta 0:00:04\n",
            "     - -------------------------------------- 2.1/44.8 MB 14.8 MB/s eta 0:00:03\n",
            "     -- ------------------------------------- 2.7/44.8 MB 14.2 MB/s eta 0:00:03\n",
            "     --- ------------------------------------ 3.7/44.8 MB 14.9 MB/s eta 0:00:03\n",
            "     --- ------------------------------------ 4.1/44.8 MB 15.5 MB/s eta 0:00:03\n",
            "     ---- ----------------------------------- 4.6/44.8 MB 13.9 MB/s eta 0:00:03\n",
            "     ---- ----------------------------------- 5.2/44.8 MB 14.0 MB/s eta 0:00:03\n",
            "     ----- ---------------------------------- 5.7/44.8 MB 13.5 MB/s eta 0:00:03\n",
            "     ----- ---------------------------------- 5.9/44.8 MB 13.1 MB/s eta 0:00:03\n",
            "     ----- ---------------------------------- 6.2/44.8 MB 12.9 MB/s eta 0:00:03\n",
            "     ------ --------------------------------- 6.8/44.8 MB 12.0 MB/s eta 0:00:04\n",
            "     ------ --------------------------------- 7.2/44.8 MB 12.1 MB/s eta 0:00:04\n",
            "     ------- -------------------------------- 8.0/44.8 MB 12.2 MB/s eta 0:00:04\n",
            "     ------- -------------------------------- 8.8/44.8 MB 12.4 MB/s eta 0:00:03\n",
            "     -------- ------------------------------- 9.3/44.8 MB 13.0 MB/s eta 0:00:03\n",
            "     -------- ------------------------------ 10.0/44.8 MB 13.0 MB/s eta 0:00:03\n",
            "     --------- ----------------------------- 10.7/44.8 MB 13.1 MB/s eta 0:00:03\n",
            "     ---------- ---------------------------- 11.6/44.8 MB 13.1 MB/s eta 0:00:03\n",
            "     ---------- ---------------------------- 12.1/44.8 MB 13.6 MB/s eta 0:00:03\n",
            "     ----------- --------------------------- 13.3/44.8 MB 14.2 MB/s eta 0:00:03\n",
            "     ------------ -------------------------- 14.0/44.8 MB 13.4 MB/s eta 0:00:03\n",
            "     ------------ -------------------------- 14.6/44.8 MB 14.2 MB/s eta 0:00:03\n",
            "     ------------- ------------------------- 15.5/44.8 MB 13.9 MB/s eta 0:00:03\n",
            "     -------------- ------------------------ 16.1/44.8 MB 14.6 MB/s eta 0:00:02\n",
            "     -------------- ------------------------ 16.7/44.8 MB 15.2 MB/s eta 0:00:02\n",
            "     -------------- ------------------------ 17.0/44.8 MB 16.0 MB/s eta 0:00:02\n",
            "     --------------- ----------------------- 17.6/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "     --------------- ----------------------- 18.2/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "     ---------------- ---------------------- 19.5/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "     ----------------- --------------------- 20.3/44.8 MB 15.2 MB/s eta 0:00:02\n",
            "     ------------------ -------------------- 20.7/44.8 MB 14.6 MB/s eta 0:00:02\n",
            "     ------------------ -------------------- 21.4/44.8 MB 14.6 MB/s eta 0:00:02\n",
            "     ------------------- ------------------- 22.2/44.8 MB 14.6 MB/s eta 0:00:02\n",
            "     -------------------- ------------------ 23.1/44.8 MB 14.6 MB/s eta 0:00:02\n",
            "     -------------------- ------------------ 24.0/44.8 MB 14.6 MB/s eta 0:00:02\n",
            "     --------------------- ----------------- 24.7/44.8 MB 14.2 MB/s eta 0:00:02\n",
            "     ---------------------- ---------------- 25.6/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "     ---------------------- ---------------- 26.2/44.8 MB 14.9 MB/s eta 0:00:02\n",
            "     ----------------------- --------------- 26.9/44.8 MB 15.2 MB/s eta 0:00:02\n",
            "     ------------------------ -------------- 27.7/44.8 MB 16.4 MB/s eta 0:00:02\n",
            "     ------------------------ -------------- 28.5/44.8 MB 17.3 MB/s eta 0:00:01\n",
            "     ------------------------- ------------- 29.0/44.8 MB 16.4 MB/s eta 0:00:01\n",
            "     ------------------------- ------------- 29.6/44.8 MB 15.6 MB/s eta 0:00:01\n",
            "     -------------------------- ------------ 30.3/44.8 MB 15.6 MB/s eta 0:00:01\n",
            "     -------------------------- ------------ 30.7/44.8 MB 15.6 MB/s eta 0:00:01\n",
            "     --------------------------- ----------- 31.6/44.8 MB 16.0 MB/s eta 0:00:01\n",
            "     ---------------------------- ---------- 32.4/44.8 MB 16.0 MB/s eta 0:00:01\n",
            "     ---------------------------- ---------- 33.2/44.8 MB 15.6 MB/s eta 0:00:01\n",
            "     ----------------------------- --------- 33.6/44.8 MB 15.2 MB/s eta 0:00:01\n",
            "     ----------------------------- --------- 34.2/44.8 MB 14.9 MB/s eta 0:00:01\n",
            "     ------------------------------ -------- 34.9/44.8 MB 14.9 MB/s eta 0:00:01\n",
            "     ------------------------------ -------- 35.5/44.8 MB 14.6 MB/s eta 0:00:01\n",
            "     ------------------------------- ------- 36.3/44.8 MB 14.9 MB/s eta 0:00:01\n",
            "     -------------------------------- ------ 37.0/44.8 MB 14.9 MB/s eta 0:00:01\n",
            "     -------------------------------- ------ 37.4/44.8 MB 14.9 MB/s eta 0:00:01\n",
            "     --------------------------------- ----- 38.0/44.8 MB 14.6 MB/s eta 0:00:01\n",
            "     --------------------------------- ----- 38.3/44.8 MB 14.2 MB/s eta 0:00:01\n",
            "     --------------------------------- ----- 38.6/44.8 MB 13.4 MB/s eta 0:00:01\n",
            "     ---------------------------------- ---- 39.0/44.8 MB 12.9 MB/s eta 0:00:01\n",
            "     ---------------------------------- ---- 39.5/44.8 MB 13.1 MB/s eta 0:00:01\n",
            "     ---------------------------------- ---- 40.0/44.8 MB 12.8 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 40.7/44.8 MB 12.9 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 40.9/44.8 MB 13.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 40.9/44.8 MB 13.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 40.9/44.8 MB 13.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 40.9/44.8 MB 13.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 40.9/44.8 MB 13.1 MB/s eta 0:00:01\n",
            "     ------------------------------------ -- 41.7/44.8 MB 10.1 MB/s eta 0:00:01\n",
            "     --------------------------------------  44.8/44.8 MB 12.4 MB/s eta 0:00:01\n",
            "     --------------------------------------  44.8/44.8 MB 12.4 MB/s eta 0:00:01\n",
            "     --------------------------------------- 44.8/44.8 MB 10.4 MB/s eta 0:00:00\n",
            "Collecting joblib>=1.2.0\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "     ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
            "     -------------------------------------- 301.8/301.8 kB 9.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\peterbenzoni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.1)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import Counter\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout,BatchNormalization,MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a16RGOC4-xjw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pwd' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_images(directory, num_files=5):\n",
        "    images = []\n",
        "    file_list = os.listdir(directory)[:num_files]  # Load only the first 5 files\n",
        "\n",
        "    for filename in tqdm(file_list, desc=f\"Loading images from {directory}\"):\n",
        "        img_path = os.path.join(directory, filename)\n",
        "        img = Image.open(img_path)\n",
        "        img = img.resize((150, 150))  # Resize image to 150 x 150\n",
        "        images.append(img)\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Paths\n",
        "\n",
        "buildings_train = './seg_train/buildings'\n",
        "forest_train = './seg_train/forest'\n",
        "glacier_train = './seg_train/glacier'\n",
        "mountain_train = './seg_train/mountain'\n",
        "sea_train = './seg_train/sea'\n",
        "street_train = './seg_train/street'\n",
        "\n",
        "buildings_test = './seg_test/buildings'\n",
        "forest_test = './seg_test/forest'\n",
        "glacier_test = './seg_test/glacier'\n",
        "mountain_test = './seg_test/mountain'\n",
        "sea_test = './seg_test/sea'\n",
        "street_test = './seg_test/street'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading images from ./seg_train/buildings: 100%|██████████| 5/5 [00:00<00:00, 120.12it/s]\n",
            "Loading images from ./seg_train/forest: 100%|██████████| 5/5 [00:00<00:00, 1666.26it/s]\n",
            "Loading images from ./seg_train/glacier: 100%|██████████| 5/5 [00:00<?, ?it/s]\n",
            "Loading images from ./seg_train/mountain: 100%|██████████| 5/5 [00:00<00:00, 1204.29it/s]\n",
            "Loading images from ./seg_train/sea: 100%|██████████| 5/5 [00:00<00:00, 1848.69it/s]\n",
            "Loading images from ./seg_train/street: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load images from each category\n",
        "buildings_img = load_images(buildings_train)\n",
        "forest_img = load_images(forest_train)\n",
        "glacier_img = load_images(glacier_train)\n",
        "mountain_img = load_images(mountain_train)\n",
        "sea_img = load_images(sea_train)\n",
        "street_img = load_images(street_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>,\n",
              " <PIL.Image.Image image mode=RGB size=150x150>]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buildings_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(datasets):\n",
        "    \n",
        "    output = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        images, labels = [], []\n",
        "        print(f\"Loading {dataset}...\")\n",
        "        i = 0\n",
        "        for folder in os.listdir(dataset):\n",
        "            label = i # Converting word labels to int (i.e. buildings = 0)\n",
        "            i = i+1\n",
        "            folder_path = os.path.join(dataset, folder)\n",
        "\n",
        "            for file in tqdm(os.listdir(folder_path), desc=f\"Processing {folder}\"):\n",
        "                img_path = os.path.join(folder_path, file)\n",
        "\n",
        "                image = Image.open(img_path).resize((150, 150))\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                \n",
        "        images = np.stack(images)\n",
        "        labels = np.array(labels, dtype='int32')\n",
        "        output.append((images, labels))\n",
        "        \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = [\"C:\\\\Users\\\\PeterBenzoni\\\\repo\\\\w281_Fall2024_FinalProject_Brown_Benzoni_Olaya\\\\seg_train\", \n",
        "        \"C:\\\\Users\\\\PeterBenzoni\\\\repo\\w281_Fall2024_FinalProject_Brown_Benzoni_Olaya\\\\seg_train\"]\n",
        "\n",
        "\n",
        "train_path, test_path = datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = load_data(datasets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalization\n",
        "train_images = train_images / 255.0 \n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 2191, 1: 2271, 2: 2404, 3: 2512, 4: 2274, 5: 2382}\n"
          ]
        }
      ],
      "source": [
        "# Training Data Distribution\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2339.0\n"
          ]
        }
      ],
      "source": [
        "avg = sum(counts)/len(unique)\n",
        "print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 2191, 1: 2271, 2: 2404, 3: 2512, 4: 2274, 5: 2382}\n"
          ]
        }
      ],
      "source": [
        "# Test Data Distribution\n",
        "test_unique, test_counts = np.unique(test_labels, return_counts=True)\n",
        "print(dict(zip(test_unique, test_counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2339.0\n"
          ]
        }
      ],
      "source": [
        "test_avg = sum(test_counts)/len(test_unique)\n",
        "print(test_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14034 images belonging to 6 classes.\n",
            "Found 14034 images belonging to 6 classes.\n",
            "Training Random Forest Classifier...\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.40      0.46       436\n",
            "           1       0.72      0.85      0.78       453\n",
            "           2       0.54      0.59      0.56       475\n",
            "           3       0.62      0.68      0.65       535\n",
            "           4       0.51      0.41      0.45       477\n",
            "           5       0.61      0.64      0.63       431\n",
            "\n",
            "    accuracy                           0.60      2807\n",
            "   macro avg       0.59      0.59      0.59      2807\n",
            "weighted avg       0.59      0.60      0.59      2807\n",
            "\n",
            "Accuracy: 0.5963662272889205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PeterBenzoni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 284ms/step - accuracy: 0.5504 - loss: 1.1309 - val_accuracy: 0.7448 - val_loss: 0.6924\n",
            "Epoch 2/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 312ms/step - accuracy: 0.7867 - loss: 0.6023 - val_accuracy: 0.8137 - val_loss: 0.5020\n",
            "Epoch 3/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 259ms/step - accuracy: 0.8491 - loss: 0.4130 - val_accuracy: 0.9127 - val_loss: 0.2723\n",
            "Epoch 4/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 249ms/step - accuracy: 0.9002 - loss: 0.2800 - val_accuracy: 0.9461 - val_loss: 0.1760\n",
            "Epoch 5/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 252ms/step - accuracy: 0.9420 - loss: 0.1628 - val_accuracy: 0.9528 - val_loss: 0.1378\n",
            "Epoch 6/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 270ms/step - accuracy: 0.9692 - loss: 0.1013 - val_accuracy: 0.9803 - val_loss: 0.0712\n",
            "Epoch 7/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 277ms/step - accuracy: 0.9806 - loss: 0.0628 - val_accuracy: 0.9803 - val_loss: 0.0591\n",
            "Epoch 8/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 275ms/step - accuracy: 0.9807 - loss: 0.0646 - val_accuracy: 0.9913 - val_loss: 0.0340\n",
            "Epoch 9/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 279ms/step - accuracy: 0.9850 - loss: 0.0464 - val_accuracy: 0.9943 - val_loss: 0.0230\n",
            "Epoch 10/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 268ms/step - accuracy: 0.9921 - loss: 0.0291 - val_accuracy: 0.9843 - val_loss: 0.0481\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 71ms/step - accuracy: 0.9867 - loss: 0.0429\n",
            "CNN Model Accuracy: 98.43%\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 1s/step - accuracy: 0.4359 - loss: 2.5751 - val_accuracy: 0.6110 - val_loss: 0.9525\n",
            "Epoch 2/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 1s/step - accuracy: 0.6356 - loss: 0.9203 - val_accuracy: 0.6244 - val_loss: 0.9346\n",
            "Epoch 3/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 1s/step - accuracy: 0.6710 - loss: 0.8454 - val_accuracy: 0.6801 - val_loss: 0.8164\n",
            "Epoch 4/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 1s/step - accuracy: 0.6903 - loss: 0.7983 - val_accuracy: 0.6789 - val_loss: 0.7644\n",
            "Epoch 5/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 1s/step - accuracy: 0.6877 - loss: 0.7859 - val_accuracy: 0.6892 - val_loss: 0.7312\n",
            "Epoch 6/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 1s/step - accuracy: 0.6955 - loss: 0.7523 - val_accuracy: 0.6915 - val_loss: 0.7788\n",
            "Epoch 7/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 1s/step - accuracy: 0.7097 - loss: 0.7426 - val_accuracy: 0.6600 - val_loss: 0.8492\n",
            "Epoch 8/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 1s/step - accuracy: 0.7135 - loss: 0.7289 - val_accuracy: 0.7113 - val_loss: 0.7501\n",
            "Epoch 9/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 1s/step - accuracy: 0.7243 - loss: 0.7062 - val_accuracy: 0.6607 - val_loss: 0.8186\n",
            "Epoch 10/10\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 1s/step - accuracy: 0.7189 - loss: 0.7264 - val_accuracy: 0.7342 - val_loss: 0.6758\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 510ms/step - accuracy: 0.7279 - loss: 0.6852\n",
            "ResNet50 Model Accuracy: 73.42%\n",
            "\n",
            "Model Performance Summary:\n",
            "Random Forest Model Accuracy: 59.64%\n",
            "CNN Model Accuracy: 98.43%\n",
            "ResNet50 Model Accuracy: 73.42%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Prepare data using ImageDataGenerator\n",
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = data_gen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Extract data for RandomForest Classifier\n",
        "train_images, train_labels = [], []\n",
        "for i in range(len(train_generator)):\n",
        "    x, y = train_generator[i]\n",
        "    train_images.extend(x)\n",
        "    train_labels.extend(y)\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Preprocess the labels\n",
        "le = LabelEncoder()\n",
        "train_labels_rf = le.fit_transform(np.argmax(train_labels, axis=1))\n",
        "\n",
        "# Split the training data for Random Forest\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(train_images.reshape(len(train_images), -1), train_labels_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForest Model\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Evaluate RandomForest\n",
        "y_pred_rf = rf.predict(X_test_rf)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test_rf, y_pred_rf))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_rf, y_pred_rf))\n",
        "\n",
        "# Define a simple CNN Model\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the CNN model\n",
        "cnn_model = create_cnn_model((150, 150, 3), train_generator.num_classes)\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN Model\n",
        "cnn_model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
        "\n",
        "# Evaluate the CNN Model\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(test_generator)\n",
        "print(f\"CNN Model Accuracy: {cnn_accuracy * 100:.2f}%\")\n",
        "\n",
        "# ResNet50 Transfer Learning Model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "output = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "resnet_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the ResNet model\n",
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ResNet Model\n",
        "resnet_model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
        "\n",
        "# Evaluate the ResNet Model\n",
        "resnet_loss, resnet_accuracy = resnet_model.evaluate(test_generator)\n",
        "print(f\"ResNet50 Model Accuracy: {resnet_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Summary of Model Performances\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "print(f\"Random Forest Model Accuracy: {accuracy_score(y_test_rf, y_pred_rf) * 100:.2f}%\")\n",
        "print(f\"CNN Model Accuracy: {cnn_accuracy * 100:.2f}%\")\n",
        "print(f\"ResNet50 Model Accuracy: {resnet_accuracy * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
